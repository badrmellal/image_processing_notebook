{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "",
   "id": "1a06b5afd116712"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "!pip install -q transformers datasets accelerate pillow requests tqdm pandas\n",
    "!pip install -q torch torchvision\n",
    "!pip install -q huggingface_hub"
   ],
   "id": "dbb1ce5eb6bb99f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T11:11:03.232728Z",
     "start_time": "2026-01-20T11:10:58.699870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install -q transformers datasets accelerate pillow requests tqdm pandas\n",
    "!pip install -q torch torchvision scikit-learn\n",
    "!pip install -q huggingface_hub"
   ],
   "id": "d5eaa81338bb7555",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T11:11:03.307299Z",
     "start_time": "2026-01-20T11:11:03.304925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json"
   ],
   "id": "91d73c2b935cfb0",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load quoran dataset",
   "id": "f79ff6f369fb2f22"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T11:11:05.473572Z",
     "start_time": "2026-01-20T11:11:03.367731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the Quran dataset from Hugging Face\n",
    "dataset = load_dataset(\"mohammed-almaamari/quran-dataset\", split=\"train\")\n",
    "\n",
    "# Convert to pandas for easier manipulation\n",
    "df = dataset.to_pandas()\n",
    "\n",
    "print(f\"Dataset loaded with {len(df)} rows\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "df.head()"
   ],
   "id": "d161a2e15399041",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with 6236 rows\n",
      "Columns: ['audio_path', 'surah_number', 'surah_name', 'surah_english_name', 'surah_english_translation', 'revelation_type', 'aya_number', 'aya_text', 'page', 'juz_number', 'manzil', 'hizb_number', 'ruku_number', 'quarter_number', 'sajda', 'aya_image']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                          audio_path  surah_number  \\\n",
       "0  https://everyayah.com/data/Muhammad_Ayyoub_128...             1   \n",
       "1  https://everyayah.com/data/Muhammad_Ayyoub_128...             1   \n",
       "2  https://everyayah.com/data/Muhammad_Ayyoub_128...             1   \n",
       "3  https://everyayah.com/data/Muhammad_Ayyoub_128...             1   \n",
       "4  https://everyayah.com/data/Muhammad_Ayyoub_128...             1   \n",
       "\n",
       "             surah_name surah_english_name surah_english_translation  \\\n",
       "0  سُورَةُ ٱلْفَاتِحَةِ         Al-Faatiha               The Opening   \n",
       "1  سُورَةُ ٱلْفَاتِحَةِ         Al-Faatiha               The Opening   \n",
       "2  سُورَةُ ٱلْفَاتِحَةِ         Al-Faatiha               The Opening   \n",
       "3  سُورَةُ ٱلْفَاتِحَةِ         Al-Faatiha               The Opening   \n",
       "4  سُورَةُ ٱلْفَاتِحَةِ         Al-Faatiha               The Opening   \n",
       "\n",
       "  revelation_type  aya_number                                  aya_text  page  \\\n",
       "0          Meccan           1    بِسْمِ اللَّهِ الرَّحْمَٰنِ الرَّحِيمِ     1   \n",
       "1          Meccan           2     الْحَمْدُ لِلَّهِ رَبِّ الْعَالَمِينَ     1   \n",
       "2          Meccan           3                   الرَّحْمَٰنِ الرَّحِيمِ     1   \n",
       "3          Meccan           4                   مَالِكِ يَوْمِ الدِّينِ     1   \n",
       "4          Meccan           5  إِيَّاكَ نَعْبُدُ وَإِيَّاكَ نَسْتَعِينُ     1   \n",
       "\n",
       "   juz_number  manzil  hizb_number  ruku_number  quarter_number sajda  \\\n",
       "0           1       1            1            1               1  None   \n",
       "1           1       1            1            1               1  None   \n",
       "2           1       1            1            1               1  None   \n",
       "3           1       1            1            1               1  None   \n",
       "4           1       1            1            1               1  None   \n",
       "\n",
       "                                           aya_image  \n",
       "0  https://surahquran.com/img/Ayat-green/verse-1-...  \n",
       "1  https://surahquran.com/img/Ayat-green/verse-2-...  \n",
       "2  https://surahquran.com/img/Ayat-green/verse-3-...  \n",
       "3  https://surahquran.com/img/Ayat-green/verse-4-...  \n",
       "4  https://surahquran.com/img/Ayat-green/verse-5-...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_path</th>\n",
       "      <th>surah_number</th>\n",
       "      <th>surah_name</th>\n",
       "      <th>surah_english_name</th>\n",
       "      <th>surah_english_translation</th>\n",
       "      <th>revelation_type</th>\n",
       "      <th>aya_number</th>\n",
       "      <th>aya_text</th>\n",
       "      <th>page</th>\n",
       "      <th>juz_number</th>\n",
       "      <th>manzil</th>\n",
       "      <th>hizb_number</th>\n",
       "      <th>ruku_number</th>\n",
       "      <th>quarter_number</th>\n",
       "      <th>sajda</th>\n",
       "      <th>aya_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://everyayah.com/data/Muhammad_Ayyoub_128...</td>\n",
       "      <td>1</td>\n",
       "      <td>سُورَةُ ٱلْفَاتِحَةِ</td>\n",
       "      <td>Al-Faatiha</td>\n",
       "      <td>The Opening</td>\n",
       "      <td>Meccan</td>\n",
       "      <td>1</td>\n",
       "      <td>بِسْمِ اللَّهِ الرَّحْمَٰنِ الرَّحِيمِ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>https://surahquran.com/img/Ayat-green/verse-1-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://everyayah.com/data/Muhammad_Ayyoub_128...</td>\n",
       "      <td>1</td>\n",
       "      <td>سُورَةُ ٱلْفَاتِحَةِ</td>\n",
       "      <td>Al-Faatiha</td>\n",
       "      <td>The Opening</td>\n",
       "      <td>Meccan</td>\n",
       "      <td>2</td>\n",
       "      <td>الْحَمْدُ لِلَّهِ رَبِّ الْعَالَمِينَ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>https://surahquran.com/img/Ayat-green/verse-2-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://everyayah.com/data/Muhammad_Ayyoub_128...</td>\n",
       "      <td>1</td>\n",
       "      <td>سُورَةُ ٱلْفَاتِحَةِ</td>\n",
       "      <td>Al-Faatiha</td>\n",
       "      <td>The Opening</td>\n",
       "      <td>Meccan</td>\n",
       "      <td>3</td>\n",
       "      <td>الرَّحْمَٰنِ الرَّحِيمِ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>https://surahquran.com/img/Ayat-green/verse-3-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://everyayah.com/data/Muhammad_Ayyoub_128...</td>\n",
       "      <td>1</td>\n",
       "      <td>سُورَةُ ٱلْفَاتِحَةِ</td>\n",
       "      <td>Al-Faatiha</td>\n",
       "      <td>The Opening</td>\n",
       "      <td>Meccan</td>\n",
       "      <td>4</td>\n",
       "      <td>مَالِكِ يَوْمِ الدِّينِ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>https://surahquran.com/img/Ayat-green/verse-4-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://everyayah.com/data/Muhammad_Ayyoub_128...</td>\n",
       "      <td>1</td>\n",
       "      <td>سُورَةُ ٱلْفَاتِحَةِ</td>\n",
       "      <td>Al-Faatiha</td>\n",
       "      <td>The Opening</td>\n",
       "      <td>Meccan</td>\n",
       "      <td>5</td>\n",
       "      <td>إِيَّاكَ نَعْبُدُ وَإِيَّاكَ نَسْتَعِينُ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>https://surahquran.com/img/Ayat-green/verse-5-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "dataset structure",
   "id": "2a605377263bd5d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T11:11:05.550181Z",
     "start_time": "2026-01-20T11:11:05.546683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Dataset Schema:\")\n",
    "print(\"-\" * 50)\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].dtype}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Sample row:\")\n",
    "print(df.iloc[0].to_dict())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"Total Surahs: {df['surah_number'].nunique()}\")\n",
    "print(f\"Total Ayahs: {len(df)}\")\n",
    "print(f\"Revelation types: {df['revelation_type'].unique()}\")"
   ],
   "id": "42fbeb7352fc5c53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Schema:\n",
      "--------------------------------------------------\n",
      "audio_path: object\n",
      "surah_number: int64\n",
      "surah_name: object\n",
      "surah_english_name: object\n",
      "surah_english_translation: object\n",
      "revelation_type: object\n",
      "aya_number: int64\n",
      "aya_text: object\n",
      "page: int64\n",
      "juz_number: int64\n",
      "manzil: int64\n",
      "hizb_number: int64\n",
      "ruku_number: int64\n",
      "quarter_number: int64\n",
      "sajda: object\n",
      "aya_image: object\n",
      "\n",
      "==================================================\n",
      "Sample row:\n",
      "{'audio_path': 'https://everyayah.com/data/Muhammad_Ayyoub_128kbps/001001.mp3', 'surah_number': 1, 'surah_name': 'سُورَةُ ٱلْفَاتِحَةِ', 'surah_english_name': 'Al-Faatiha', 'surah_english_translation': 'The Opening', 'revelation_type': 'Meccan', 'aya_number': 1, 'aya_text': 'بِسْمِ اللَّهِ الرَّحْمَٰنِ الرَّحِيمِ', 'page': 1, 'juz_number': 1, 'manzil': 1, 'hizb_number': 1, 'ruku_number': 1, 'quarter_number': 1, 'sajda': None, 'aya_image': 'https://surahquran.com/img/Ayat-green/verse-1-surah-1.png'}\n",
      "\n",
      "==================================================\n",
      "Total Surahs: 114\n",
      "Total Ayahs: 6236\n",
      "Revelation types: ['Meccan' 'Medinan']\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T11:11:05.619855Z",
     "start_time": "2026-01-20T11:11:05.607329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import hashlib\n",
    "\n",
    "def download_image(url, cache_dir=\"./quran_images\"):\n",
    "    \"\"\"Download image from URL with caching\"\"\"\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "    # Create cache filename from URL hash\n",
    "    url_hash = hashlib.md5(url.encode()).hexdigest()\n",
    "    cache_path = os.path.join(cache_dir, f\"{url_hash}.png\")\n",
    "\n",
    "    # Check if already cached\n",
    "    if os.path.exists(cache_path):\n",
    "        try:\n",
    "            return Image.open(cache_path).convert(\"RGB\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Download image\n",
    "    try:\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "        img.save(cache_path)\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test downloading a single image\n",
    "test_url = df['aya_image'].iloc[0]\n",
    "print(f\"Testing image download: {test_url}\")\n",
    "test_img = download_image(test_url)\n",
    "if test_img:\n",
    "    print(f\"Success! Image size: {test_img.size}\")\n",
    "    display(test_img.resize((300, 100)))"
   ],
   "id": "5e2d057b7ff455b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing image download: https://surahquran.com/img/Ayat-green/verse-1-surah-1.png\n",
      "Success! Image size: (1080, 477)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=300x100>"
      ],
      "image/png": "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",
      "image/jpeg": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T11:11:05.820753Z",
     "start_time": "2026-01-20T11:11:05.702743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_ocr_sample(row):\n",
    "    \"\"\"Create an OCR training sample from a dataset row\"\"\"\n",
    "\n",
    "    # The image shows the ayah text, model should extract it\n",
    "    prompt = \"<image>\\nاستخرج النص القرآني من هذه الصورة.\"\n",
    "\n",
    "    # The expected output is the ayah text with metadata\n",
    "    response = f\"\"\"النص: {row['aya_text']}\n",
    "السورة: {row['surah_name']} ({row['surah_english_name']})\n",
    "رقم الآية: {row['aya_number']}\n",
    "الصفحة: {row['page']}\n",
    "الجزء: {row['juz_number']}\n",
    "الحزب: {row['hizb_number']}\"\"\"\n",
    "\n",
    "    if pd.notna(row['sajda']) and row['sajda']:\n",
    "        response += f\"\\nسجدة: {row['sajda']}\"\n",
    "\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"response\": response,\n",
    "        \"image_url\": row['aya_image'],\n",
    "        \"surah_number\": row['surah_number'],\n",
    "        \"aya_number\": row['aya_number'],\n",
    "        \"aya_text\": row['aya_text']\n",
    "    }\n",
    "\n",
    "# Create samples for all rows\n",
    "samples = []\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Creating samples\"):\n",
    "    sample = create_ocr_sample(row)\n",
    "    samples.append(sample)\n",
    "\n",
    "print(f\"Created {len(samples)} training samples\")\n",
    "print(\"\\nExample sample:\")\n",
    "print(json.dumps(samples[0], ensure_ascii=False, indent=2))"
   ],
   "id": "343bd4e3df3e20ed",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating samples: 100%|██████████| 6236/6236 [00:00<00:00, 55978.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 6236 training samples\n",
      "\n",
      "Example sample:\n",
      "{\n",
      "  \"prompt\": \"<image>\\nاستخرج النص القرآني من هذه الصورة.\",\n",
      "  \"response\": \"النص: بِسْمِ اللَّهِ الرَّحْمَٰنِ الرَّحِيمِ\\nالسورة: سُورَةُ ٱلْفَاتِحَةِ (Al-Faatiha)\\nرقم الآية: 1\\nالصفحة: 1\\nالجزء: 1\\nالحزب: 1\",\n",
      "  \"image_url\": \"https://surahquran.com/img/Ayat-green/verse-1-surah-1.png\",\n",
      "  \"surah_number\": 1,\n",
      "  \"aya_number\": 1,\n",
      "  \"aya_text\": \"بِسْمِ اللَّهِ الرَّحْمَٰنِ الرَّحِيمِ\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T11:11:05.831886Z",
     "start_time": "2026-01-20T11:11:05.825393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_multi_task_samples(row):\n",
    "    \"\"\"Create multiple task variations for each ayah\"\"\"\n",
    "    samples = []\n",
    "\n",
    "    # Task 1: Simple OCR - Extract text only\n",
    "    samples.append({\n",
    "        \"task\": \"ocr\",\n",
    "        \"prompt\": \"<image>\\nExtract the Quranic text from this image.\",\n",
    "        \"response\": row['aya_text'],\n",
    "        \"image_url\": row['aya_image']\n",
    "    })\n",
    "\n",
    "    # Task 2: Full metadata extraction\n",
    "    samples.append({\n",
    "        \"task\": \"metadata\",\n",
    "        \"prompt\": \"<image>\\nExtract all information from this Quran ayah image.\",\n",
    "        \"response\": f\"\"\"Ayah Text: {row['aya_text']}\n",
    "Surah: {row['surah_name']} ({row['surah_english_translation']})\n",
    "Surah Number: {row['surah_number']}\n",
    "Ayah Number: {row['aya_number']}\n",
    "Page: {row['page']}\n",
    "Juz: {row['juz_number']}\n",
    "Hizb: {row['hizb_number']}\n",
    "Manzil: {row['manzil']}\n",
    "Ruku: {row['ruku_number']}\n",
    "Quarter: {row['quarter_number']}\n",
    "Revelation Type: {row['revelation_type']}\"\"\",\n",
    "        \"image_url\": row['aya_image']\n",
    "    })\n",
    "\n",
    "    # Task 3: Arabic OCR\n",
    "    samples.append({\n",
    "        \"task\": \"arabic_ocr\",\n",
    "        \"prompt\": \"<image>\\nاقرأ النص العربي في هذه الصورة.\",\n",
    "        \"response\": row['aya_text'],\n",
    "        \"image_url\": row['aya_image']\n",
    "    })\n",
    "\n",
    "    return samples\n",
    "\n",
    "# Create multi-task samples for a subset\n",
    "multi_task_samples = []\n",
    "for idx, row in tqdm(df.head(100).iterrows(), total=100, desc=\"Creating multi-task samples\"):\n",
    "    multi_task_samples.extend(create_multi_task_samples(row))\n",
    "\n",
    "print(f\"Created {len(multi_task_samples)} multi-task samples from 100 ayahs\")"
   ],
   "id": "ce16198be61f39cb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating multi-task samples: 100%|██████████| 100/100 [00:00<00:00, 39261.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 300 multi-task samples from 100 ayahs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T11:11:05.926390Z",
     "start_time": "2026-01-20T11:11:05.919793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predownload_images(df, cache_dir=\"./quran_images\", max_images=None):\n",
    "    \"\"\"Pre-download all images to local cache\"\"\"\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "    urls = df['aya_image'].tolist()\n",
    "    if max_images:\n",
    "        urls = urls[:max_images]\n",
    "\n",
    "    successful = 0\n",
    "    failed = 0\n",
    "\n",
    "    for url in tqdm(urls, desc=\"Downloading images\"):\n",
    "        try:\n",
    "            url_hash = hashlib.md5(url.encode()).hexdigest()\n",
    "            cache_path = os.path.join(cache_dir, f\"{url_hash}.png\")\n",
    "\n",
    "            if os.path.exists(cache_path):\n",
    "                successful += 1\n",
    "                continue\n",
    "\n",
    "            response = requests.get(url, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "            img.save(cache_path)\n",
    "            successful += 1\n",
    "        except Exception as e:\n",
    "            failed += 1\n",
    "\n",
    "    print(f\"Downloaded: {successful}, Failed: {failed}\")\n",
    "    return successful, failed\n",
    "\n",
    "# Download first 500 images\n",
    "predownload_images(df, max_images=500)"
   ],
   "id": "c002e176b4abd67",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images: 100%|██████████| 500/500 [00:00<00:00, 232011.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: 500, Failed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T11:11:05.985955Z",
     "start_time": "2026-01-20T11:11:05.974009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_training_data(samples, output_path=\"quran_ocr_training.json\"):\n",
    "    \"\"\"Save training samples to JSON format\"\"\"\n",
    "\n",
    "    # Format for training\n",
    "    training_data = []\n",
    "    for sample in samples:\n",
    "        training_data.append({\n",
    "            \"conversations\": [\n",
    "                {\n",
    "                    \"role\": \"<|User|>\",\n",
    "                    \"content\": sample['prompt'],\n",
    "                    \"images\": [sample['image_url']]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"<|Assistant|>\",\n",
    "                    \"content\": sample['response']\n",
    "                }\n",
    "            ]\n",
    "        })\n",
    "\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(training_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"Saved {len(training_data)} samples to {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "# Save training data\n",
    "save_training_data(samples[:1000], \"quran_ocr_training.json\")"
   ],
   "id": "ac04dd32b725662d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1000 samples to quran_ocr_training.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'quran_ocr_training.json'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T11:11:11.552581Z",
     "start_time": "2026-01-20T11:11:06.031551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create stratified split by surah\n",
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=df['surah_number']\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "\n",
    "# Create samples for each split\n",
    "train_samples = [create_ocr_sample(row) for _, row in tqdm(train_df.iterrows(), total=len(train_df))]\n",
    "val_samples = [create_ocr_sample(row) for _, row in tqdm(val_df.iterrows(), total=len(val_df))]\n",
    "\n",
    "# Save splits\n",
    "save_training_data(train_samples, \"quran_ocr_train.json\")\n",
    "save_training_data(val_samples, \"quran_ocr_val.json\")"
   ],
   "id": "1d79e502cd586f52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 5612\n",
      "Validation samples: 624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5612/5612 [00:00<00:00, 47353.03it/s]\n",
      "100%|██████████| 624/624 [00:00<00:00, 52152.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 5612 samples to quran_ocr_train.json\n",
      "Saved 624 samples to quran_ocr_val.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'quran_ocr_val.json'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T11:11:13.622416Z",
     "start_time": "2026-01-20T11:11:11.599661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model configuration\n",
    "model_path = \"prithivMLmods/DeepSeek-OCR-Latest-BF16.I64\"\n",
    "\n",
    "# Check GPU availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(f\"Tokenizer loaded with vocab size: {tokenizer.vocab_size}\")"
   ],
   "id": "fecba40f5bd6e3d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e2436f43cc4e4ddb9be1a874483417a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f366751b8fcb49b3abbdf6f33ad3c2cf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/549 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc233177a13244c6a82b515922fe3ea0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded with vocab size: 128000\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-20T11:11:15.941829Z",
     "start_time": "2026-01-20T11:11:13.672673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# Quantization config for memory efficiency\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "print(\"Model loaded successfully\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()) / 1e9:.2f}B\")"
   ],
   "id": "d204397de3778d86",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8d151d0b2f1b419ea2dace6cb4d8b613"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "modeling_deepseekocr.py: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "367cc77184c849f99025b46c2a82375b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "deepencoder.py: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee444ad20a024b5a86689a31ec3cfca0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/prithivMLmods/DeepSeek-OCR-Latest-BF16.I64:\n",
      "- deepencoder.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "conversation.py: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88b89a8e1d3b4b818ef14efc31d98abb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/prithivMLmods/DeepSeek-OCR-Latest-BF16.I64:\n",
      "- conversation.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/prithivMLmods/DeepSeek-OCR-Latest-BF16.I64:\n",
      "- modeling_deepseekocr.py\n",
      "- deepencoder.py\n",
      "- conversation.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers_modules.prithivMLmods.DeepSeek-OCR-Latest-BF16'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[40]\u001B[39m\u001B[32m, line 12\u001B[39m\n\u001B[32m      4\u001B[39m bnb_config = BitsAndBytesConfig(\n\u001B[32m      5\u001B[39m     load_in_4bit=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m      6\u001B[39m     bnb_4bit_quant_type=\u001B[33m\"\u001B[39m\u001B[33mnf4\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      7\u001B[39m     bnb_4bit_compute_dtype=torch.bfloat16,\n\u001B[32m      8\u001B[39m     bnb_4bit_use_double_quant=\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m      9\u001B[39m )\n\u001B[32m     11\u001B[39m \u001B[38;5;66;03m# Load model\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m12\u001B[39m model = \u001B[43mAutoModelForCausalLM\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m    \u001B[49m\u001B[43mquantization_config\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbnb_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mauto\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     17\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbfloat16\u001B[49m\n\u001B[32m     18\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     20\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mModel loaded successfully\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     21\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mModel parameters: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28msum\u001B[39m(p.numel()\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mp\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39mmodel.parameters())\u001B[38;5;250m \u001B[39m/\u001B[38;5;250m \u001B[39m\u001B[32m1e9\u001B[39m\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33mB\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:549\u001B[39m, in \u001B[36m_BaseAutoModelClass.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[39m\n\u001B[32m    546\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m kwargs.get(\u001B[33m\"\u001B[39m\u001B[33mquantization_config\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    547\u001B[39m     _ = kwargs.pop(\u001B[33m\"\u001B[39m\u001B[33mquantization_config\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m549\u001B[39m config, kwargs = \u001B[43mAutoConfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    550\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    551\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_unused_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    552\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcode_revision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcode_revision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    553\u001B[39m \u001B[43m    \u001B[49m\u001B[43m_commit_hash\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcommit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    554\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    555\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    556\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    558\u001B[39m \u001B[38;5;66;03m# if torch_dtype=auto was passed here, ensure to pass it on\u001B[39;00m\n\u001B[32m    559\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m kwargs_orig.get(\u001B[33m\"\u001B[39m\u001B[33mtorch_dtype\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) == \u001B[33m\"\u001B[39m\u001B[33mauto\u001B[39m\u001B[33m\"\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py:1302\u001B[39m, in \u001B[36mAutoConfig.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[39m\n\u001B[32m   1297\u001B[39m     trust_remote_code = resolve_trust_remote_code(\n\u001B[32m   1298\u001B[39m         trust_remote_code, pretrained_model_name_or_path, has_local_code, has_remote_code, upstream_repo\n\u001B[32m   1299\u001B[39m     )\n\u001B[32m   1301\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_remote_code \u001B[38;5;129;01mand\u001B[39;00m trust_remote_code:\n\u001B[32m-> \u001B[39m\u001B[32m1302\u001B[39m     config_class = \u001B[43mget_class_from_dynamic_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1303\u001B[39m \u001B[43m        \u001B[49m\u001B[43mclass_ref\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcode_revision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcode_revision\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m   1304\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1305\u001B[39m     config_class.register_for_auto_class()\n\u001B[32m   1306\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m config_class.from_pretrained(pretrained_model_name_or_path, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py:581\u001B[39m, in \u001B[36mget_class_from_dynamic_module\u001B[39m\u001B[34m(class_reference, pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, code_revision, **kwargs)\u001B[39m\n\u001B[32m    568\u001B[39m \u001B[38;5;66;03m# And lastly we get the class inside our newly created module\u001B[39;00m\n\u001B[32m    569\u001B[39m final_module = get_cached_module_file(\n\u001B[32m    570\u001B[39m     repo_id,\n\u001B[32m    571\u001B[39m     module_file + \u001B[33m\"\u001B[39m\u001B[33m.py\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    579\u001B[39m     repo_type=repo_type,\n\u001B[32m    580\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m581\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mget_class_in_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclass_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinal_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforce_reload\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharmMiscProject/.venv/lib/python3.12/site-packages/transformers/dynamic_module_utils.py:276\u001B[39m, in \u001B[36mget_class_in_module\u001B[39m\u001B[34m(class_name, module_path, force_reload)\u001B[39m\n\u001B[32m    274\u001B[39m \u001B[38;5;66;03m# reload in both cases, unless the module is already imported and the hash hits\u001B[39;00m\n\u001B[32m    275\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(module, \u001B[33m\"\u001B[39m\u001B[33m__transformers_module_hash__\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m) != module_hash:\n\u001B[32m--> \u001B[39m\u001B[32m276\u001B[39m     \u001B[43mmodule_spec\u001B[49m\u001B[43m.\u001B[49m\u001B[43mloader\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexec_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodule\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    277\u001B[39m     module.__transformers_module_hash__ = module_hash\n\u001B[32m    278\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(module, class_name)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap_external>:995\u001B[39m, in \u001B[36mexec_module\u001B[39m\u001B[34m(self, module)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen importlib._bootstrap>:488\u001B[39m, in \u001B[36m_call_with_frames_removed\u001B[39m\u001B[34m(f, *args, **kwds)\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.cache/huggingface/modules/transformers_modules/prithivMLmods/DeepSeek-OCR-Latest-BF16.I64/244823a4cf4089862aab71ce1d4883253ac4b88f/modeling_deepseekocr.py:27\u001B[39m\n\u001B[32m     25\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodels\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mllama\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodeling_llama\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m LlamaAttention, LlamaRotaryEmbedding\n\u001B[32m     26\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m TextStreamer\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdeepencoder\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m build_sam_vit_b, build_clip_l, MlpProjector\n\u001B[32m     28\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mconversation\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m get_conv_template\n\u001B[32m     30\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mload_image\u001B[39m(image_path):\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'transformers_modules.prithivMLmods.DeepSeek-OCR-Latest-BF16'"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Test inference on Quran image",
   "id": "6e9a2c57676c04d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def test_inference(model, tokenizer, image_url, prompt):\n",
    "    \"\"\"Run inference on a single image\"\"\"\n",
    "\n",
    "    # Download image\n",
    "    response = requests.get(image_url, timeout=30)\n",
    "    image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "    # Display image\n",
    "    display(image)\n",
    "\n",
    "    # Create conversation format\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"<|User|>\",\n",
    "            \"content\": prompt,\n",
    "            \"images\": [image_url]\n",
    "        },\n",
    "        {\"role\": \"<|Assistant|>\", \"content\": \"\"}\n",
    "    ]\n",
    "\n",
    "    # Run inference using model's infer method if available\n",
    "    if hasattr(model, 'infer'):\n",
    "        output = model.infer(\n",
    "            tokenizer=tokenizer,\n",
    "            prompt=prompt,\n",
    "            image_file=image_url,\n",
    "            output_path=\"./test_output\",\n",
    "            eval_mode=True\n",
    "        )\n",
    "        return output\n",
    "\n",
    "    return \"Inference method not available\"\n",
    "\n",
    "# Test on first ayah\n",
    "test_url = df['aya_image'].iloc[0]\n",
    "test_prompt = \"<image>\\nExtract the Quranic text from this image.\"\n",
    "\n",
    "print(\"Testing inference on first ayah:\")\n",
    "print(f\"Expected text: {df['aya_text'].iloc[0]}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "result = test_inference(model, tokenizer, test_url, test_prompt)\n",
    "print(f\"Model output: {result}\")"
   ],
   "id": "f95242590384db0e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "LORA finetuning",
   "id": "88e8454c5450a4f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install -q peft\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "# Prepare model for training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
    "    ],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "# Apply LoRA\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Print trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "all_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Trainable: {trainable_params:,} / {all_params:,} ({100 * trainable_params / all_params:.2f}%)\")"
   ],
   "id": "c0bc39c341674820"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Training config",
   "id": "3590bec660547f3d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./quran_ocr_finetuned\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    warmup_steps=100,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "    eval_steps=500,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_total_limit=3,\n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    dataloader_num_workers=2,\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "print(\"Training configuration set\")"
   ],
   "id": "f5381978ac28392b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Data collector",
   "id": "1e63a023f311fa4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def collate_fn(batch, tokenizer, model):\n",
    "    \"\"\"Custom collate function for Quran OCR dataset\"\"\"\n",
    "\n",
    "    prompts = []\n",
    "    responses = []\n",
    "    images = []\n",
    "\n",
    "    for sample in batch:\n",
    "        if sample['image'] is None:\n",
    "            continue\n",
    "\n",
    "        prompts.append(sample['prompt'])\n",
    "        responses.append(sample['response'])\n",
    "        images.append(sample['image'])\n",
    "\n",
    "    if not prompts:\n",
    "        return None\n",
    "\n",
    "    # Tokenize inputs\n",
    "    full_texts = [f\"{p}\\n{r}\" for p, r in zip(prompts, responses)]\n",
    "\n",
    "    encodings = tokenizer(\n",
    "        full_texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=2048,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": encodings[\"input_ids\"],\n",
    "        \"attention_mask\": encodings[\"attention_mask\"],\n",
    "        \"labels\": encodings[\"input_ids\"].clone(),\n",
    "        \"images\": images\n",
    "    }\n",
    "\n",
    "print(\"Data collator defined\")"
   ],
   "id": "d93a58535af2adc5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from functools import partial\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = QuranOCRDataset(train_samples, max_samples=1000)\n",
    "val_dataset = QuranOCRDataset(val_samples, max_samples=100)\n",
    "\n",
    "# Create collate function with tokenizer\n",
    "collate_with_tokenizer = partial(collate_fn, tokenizer=tokenizer, model=model)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_with_tokenizer,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_with_tokenizer,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")"
   ],
   "id": "d591574b72935985"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "# Scheduler\n",
    "num_training_steps = len(train_loader) * 3  # 3 epochs\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_training_steps)\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        if batch is None:\n",
    "            continue\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
    "\n",
    "    return total_loss / max(num_batches, 1)\n",
    "\n",
    "print(\"Training functions defined\")"
   ],
   "id": "b4f7439589febc42"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Run training",
   "id": "23c89e432a43ca97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_epochs = 3\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, scheduler, device)\n",
    "    print(f\"Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    num_val_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "            if batch is None:\n",
    "                continue\n",
    "\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            val_loss += outputs.loss.item()\n",
    "            num_val_batches += 1\n",
    "\n",
    "    val_loss = val_loss / max(num_val_batches, 1)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        model.save_pretrained(\"./quran_ocr_best\")\n",
    "        print(\"Saved best model!\")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ],
   "id": "c0509f7a3c75d82d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "output_dir = \"./quran_ocr_finetuned_final\"\n",
    "\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"Model saved to {output_dir}\")\n",
    "\n",
    "# List saved files\n",
    "for f in os.listdir(output_dir):\n",
    "    size = os.path.getsize(os.path.join(output_dir, f)) / 1e6\n",
    "    print(f\"  {f}: {size:.2f} MB\")"
   ],
   "id": "d65b5ab15bd3a59b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluate_ocr_accuracy(model, tokenizer, test_samples, num_samples=50):\n",
    "    \"\"\"Evaluate OCR accuracy on test samples\"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for sample in tqdm(test_samples[:num_samples], desc=\"Evaluating\"):\n",
    "        try:\n",
    "            # Download image\n",
    "            response = requests.get(sample['image_url'], timeout=30)\n",
    "            image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "            # Get prediction (simplified - would need full inference pipeline)\n",
    "            expected = sample['aya_text']\n",
    "\n",
    "            results.append({\n",
    "                \"expected\": expected,\n",
    "                \"image_url\": sample['image_url']\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    return results\n",
    "\n",
    "# Run evaluation\n",
    "eval_results = evaluate_ocr_accuracy(model, tokenizer, val_samples, num_samples=20)\n",
    "print(f\"Evaluated {len(eval_results)} samples\")"
   ],
   "id": "58e93cfc73a4e5f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_sample(sample, prediction=None):\n",
    "    \"\"\"Visualize a sample with its prediction\"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "\n",
    "    # Download and display image\n",
    "    response = requests.get(sample['image_url'], timeout=30)\n",
    "    image = Image.open(BytesIO(response.content))\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Add text below\n",
    "    title = f\"Surah: {sample.get('surah_number', 'N/A')}, Ayah: {sample.get('aya_number', 'N/A')}\"\n",
    "    ax.set_title(title, fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Expected: {sample['aya_text']}\")\n",
    "    if prediction:\n",
    "        print(f\"Predicted: {prediction}\")\n",
    "\n",
    "# Visualize a few samples\n",
    "for i in range(3):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Sample {i+1}\")\n",
    "    print('='*50)\n",
    "    visualize_sample(samples[i])"
   ],
   "id": "39a9b7db51b357c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f93ad5069f5d40fd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
